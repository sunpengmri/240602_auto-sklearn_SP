{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Extending Auto-Sklearn with Regression Component\n\nThe following example demonstrates how to create a new regression\ncomponent for using in auto-sklearn.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import Optional\nfrom pprint import pprint\n\nfrom ConfigSpace.configuration_space import ConfigurationSpace\nfrom ConfigSpace.hyperparameters import (\n    UniformFloatHyperparameter,\n    UniformIntegerHyperparameter,\n    CategoricalHyperparameter,\n)\nfrom ConfigSpace.conditions import EqualsCondition\n\nimport sklearn.metrics\n\nfrom autosklearn.askl_typing import FEAT_TYPE_TYPE\nimport autosklearn.regression\nimport autosklearn.pipeline.components.regression\nfrom autosklearn.pipeline.components.base import AutoSklearnRegressionAlgorithm\nfrom autosklearn.pipeline.constants import (\n    SPARSE,\n    DENSE,\n    SIGNED_DATA,\n    UNSIGNED_DATA,\n    PREDICTIONS,\n)\n\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implement kernel ridge regression component for auto-sklearn\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class KernelRidgeRegression(AutoSklearnRegressionAlgorithm):\n    def __init__(self, alpha, kernel, gamma, degree, coef0, random_state=None):\n        self.alpha = alpha\n        self.kernel = kernel\n        self.gamma = gamma\n        self.degree = degree\n        self.coef0 = coef0\n        self.random_state = random_state\n        self.estimator = None\n\n    def fit(self, X, y):\n        self.alpha = float(self.alpha)\n        self.gamma = float(self.gamma)\n        self.degree = int(self.degree)\n        self.coef0 = float(self.coef0)\n\n        import sklearn.kernel_ridge\n\n        self.estimator = sklearn.kernel_ridge.KernelRidge(\n            alpha=self.alpha,\n            kernel=self.kernel,\n            gamma=self.gamma,\n            degree=self.degree,\n            coef0=self.coef0,\n        )\n        self.estimator.fit(X, y)\n        return self\n\n    def predict(self, X):\n        if self.estimator is None:\n            raise NotImplementedError\n        return self.estimator.predict(X)\n\n    @staticmethod\n    def get_properties(dataset_properties=None):\n        return {\n            \"shortname\": \"KRR\",\n            \"name\": \"Kernel Ridge Regression\",\n            \"handles_regression\": True,\n            \"handles_classification\": False,\n            \"handles_multiclass\": False,\n            \"handles_multilabel\": False,\n            \"handles_multioutput\": True,\n            \"is_deterministic\": True,\n            \"input\": (SPARSE, DENSE, UNSIGNED_DATA, SIGNED_DATA),\n            \"output\": (PREDICTIONS,),\n        }\n\n    @staticmethod\n    def get_hyperparameter_search_space(\n        feat_type: Optional[FEAT_TYPE_TYPE] = None, dataset_properties=None\n    ):\n        cs = ConfigurationSpace()\n        alpha = UniformFloatHyperparameter(\n            name=\"alpha\", lower=10**-5, upper=1, log=True, default_value=1.0\n        )\n        kernel = CategoricalHyperparameter(\n            name=\"kernel\",\n            # We restrict ourselves to two possible kernels for this example\n            choices=[\"polynomial\", \"rbf\"],\n            default_value=\"polynomial\",\n        )\n        gamma = UniformFloatHyperparameter(\n            name=\"gamma\", lower=0.00001, upper=1, default_value=0.1, log=True\n        )\n        degree = UniformIntegerHyperparameter(\n            name=\"degree\", lower=2, upper=5, default_value=3\n        )\n        coef0 = UniformFloatHyperparameter(\n            name=\"coef0\",\n            lower=1e-2,\n            upper=1e2,\n            log=True,\n            default_value=1,\n        )\n        cs.add_hyperparameters([alpha, kernel, gamma, degree, coef0])\n        degree_condition = EqualsCondition(degree, kernel, \"polynomial\")\n        coef0_condition = EqualsCondition(coef0, kernel, \"polynomial\")\n        cs.add_conditions([degree_condition, coef0_condition])\n        return cs\n\n\n# Add KRR component to auto-sklearn.\nautosklearn.pipeline.components.regression.add_regressor(KernelRidgeRegression)\ncs = KernelRidgeRegression.get_hyperparameter_search_space()\nprint(cs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = load_diabetes(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit the model using KRR\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg = autosklearn.regression.AutoSklearnRegressor(\n    time_left_for_this_task=30,\n    per_run_time_limit=10,\n    include={\"regressor\": [\"KernelRidgeRegression\"]},\n    # Bellow two flags are provided to speed up calculations\n    # Not recommended for a real implementation\n    initial_configurations_via_metalearning=0,\n    smac_scenario_args={\"runcount_limit\": 5},\n)\nreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print prediction score and statistics\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = reg.predict(X_test)\nprint(\"r2 score: \", sklearn.metrics.r2_score(y_pred, y_test))\npprint(reg.show_models(), indent=4)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}