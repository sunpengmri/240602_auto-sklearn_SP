{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Performance-over-time plot\nThis example shows, how to use the *performance_over_time_* attribute to plot the performance\nover train time.  *performance_over_time_* can contain multiple metrics within a pandas dataframe, namely:\n\n    - ensemble_optimization_score\n    - ensemble_test_score\n    - single_best_optimization_score\n    - single_best_test_score\n    - single_best_train_score\n\n*auto-sklearn* can automatically encode categorical columns using a label/ordinal encoder.\nThis example highlights how to properly set the dtype in a DataFrame for this to happen,\nand showcase how to input also testing data to autosklearn.\n\nThe X_train/y_train arguments to the fit function will be used to fit the scikit-learn model,\nwhereas the X_test/y_test will be used to evaluate how good this scikit-learn model generalizes\nto unseen data (i.e. data not in X_train/y_train). Using test data is a good mechanism to measure\nif the trained model suffers from overfit, and more details can be found on [evaluating estimator\nperformance](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).\n\nIn order to provide *\\*_test_score* metrics, X_test and y_test must be provided to the AutoML-Model, as \nshown in this example.\n\nThere is also support to manually indicate the feature types (whether a column is categorical\nor numerical) via the argument feat_types from fit(). This is important when working with\nlist or numpy arrays as there is no per-column dtype (further details in the example\n`sphx_glr_examples_40_advanced_example_feature_types.py`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn.model_selection\nimport sklearn.datasets\nimport sklearn.metrics\n\nfrom smac.tae import StatusType\n\nimport autosklearn.classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Using Australian dataset https://www.openml.org/d/40981.\n# This example will use the command fetch_openml, which will\n# download a properly formatted dataframe if you use as_frame=True.\n# For demonstration purposes, we will download a numpy array using\n# as_frame=False, and manually creating the pandas DataFrame\nX, y = sklearn.datasets.fetch_openml(data_id=40981, return_X_y=True, as_frame=False)\n\n# bool and category will be automatically encoded.\n# Targets for classification are also automatically encoded\n# If using fetch_openml, data is already properly encoded, below\n# is an example for user reference\nX = pd.DataFrame(data=X, columns=[\"A\" + str(i) for i in range(1, 15)])\ndesired_boolean_columns = [\"A1\"]\ndesired_categorical_columns = [\"A4\", \"A5\", \"A6\", \"A8\", \"A9\", \"A11\", \"A12\"]\ndesired_numerical_columns = [\"A2\", \"A3\", \"A7\", \"A10\", \"A13\", \"A14\"]\nfor column in X.columns:\n    if column in desired_boolean_columns:\n        X[column] = X[column].astype(\"bool\")\n    elif column in desired_categorical_columns:\n        X[column] = X[column].astype(\"category\")\n    else:\n        X[column] = pd.to_numeric(X[column])\n\ny = pd.DataFrame(y, dtype=\"category\")\n\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n    X, y, test_size=0.5, random_state=3\n)\nprint(X.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and fit a classifier\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cls = autosklearn.classification.AutoSklearnClassifier(\n    time_left_for_this_task=120,\n    per_run_time_limit=30,\n)\ncls.fit(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the Score of the final ensemble\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions = cls.predict(X_test)\nprint(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the ensemble performance\nThe *performance_over_time_* attribute returns a pandas dataframe, which can\nbe directly used for plotting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "poT = cls.performance_over_time_\npoT.plot(\n    x=\"Timestamp\",\n    kind=\"line\",\n    legend=True,\n    title=\"Auto-sklearn accuracy over time\",\n    grid=True,\n)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}