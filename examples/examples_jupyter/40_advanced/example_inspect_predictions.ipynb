{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Model Explanation\n\nThe following example shows how to fit a simple classification model with\n*auto-sklearn* and use the [inspect module](https://scikit-learn.org/stable/inspection.html) from\nscikit-learn to understand what affects the predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\nfrom sklearn.inspection import plot_partial_dependence, permutation_importance\nimport matplotlib.pyplot as plt\nimport autosklearn.classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Build a Model\n\nWe start by loading the \"Run or walk\" dataset from OpenML and train an auto-sklearn model on it.\nFor this dataset, the goal is to predict whether a person is running or walking based on\naccelerometer and gyroscope data collected by a phone. For more information see\n[here](https://www.openml.org/d/40922).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = sklearn.datasets.fetch_openml(data_id=40922)\n\n# Note: To speed up the example, we subsample the dataset\ndataset.data = dataset.data.sample(n=5000, random_state=1, axis=\"index\")\ndataset.target = dataset.target[dataset.data.index]\n\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n    dataset.data, dataset.target, test_size=0.3, random_state=1\n)\n\nautoml = autosklearn.classification.AutoSklearnClassifier(\n    time_left_for_this_task=120,\n    per_run_time_limit=30,\n    tmp_folder=\"/tmp/autosklearn_inspect_predictions_example_tmp\",\n)\nautoml.fit(X_train, y_train, dataset_name=\"Run_or_walk_information\")\n\ns = automl.score(X_train, y_train)\nprint(f\"Train score {s}\")\ns = automl.score(X_test, y_test)\nprint(f\"Test score {s}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute permutation importance - part 1\n\nSince auto-sklearn implements the scikit-learn interface, it can be used with the scikit-learn's\ninspection module. So, now we first look at the [permutation importance](https://christophm.github.io/interpretable-ml-book/feature-importance.html), which defines the\ndecrease in a model score when a given feature is randomly permuted. So, the higher the score,\nthe more does the model's predictions depend on this feature.\n\n**Note:** There are some pitfalls in interpreting these numbers, which can be found\nin the [scikit-learn docs](https://scikit-learn.org/stable/modules/permutation_importance.html).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r = permutation_importance(automl, X_test, y_test, n_repeats=10, random_state=0)\nsort_idx = r.importances_mean.argsort()[::-1]\n\nplt.boxplot(\n    r.importances[sort_idx].T, labels=[dataset.feature_names[i] for i in sort_idx]\n)\n\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n\nfor i in sort_idx[::-1]:\n    print(\n        f\"{dataset.feature_names[i]:10s}: {r.importances_mean[i]:.3f} +/- \"\n        f\"{r.importances_std[i]:.3f}\"\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create partial dependence (PD) and individual conditional expectation (ICE) plots - part 2\n\n[ICE plots](https://christophm.github.io/interpretable-ml-book/ice.html) describe the relation\nbetween feature values and the response value for each sample\nindividually -- it shows how the response value changes if the value of one feature is changed.\n\n[PD plots](https://christophm.github.io/interpretable-ml-book/pdp.html) describe the relation\nbetween feature values and the response value, i.e. the expected\nresponse value wrt. one or multiple input features. Since we use a classification dataset, this\ncorresponds to the predicted class probability.\n\nSince ``acceleration_y`` and ``acceleration_z`` turned out to have the largest impact on the response\nvalue according to the permutation dependence, we'll first look at them and generate a plot\ncombining ICE (thin lines) and PD (thick line)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features = [1, 2]\nplot_partial_dependence(\n    automl,\n    dataset.data,\n    features=features,\n    grid_resolution=5,\n    kind=\"both\",\n    feature_names=dataset.feature_names,\n)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create partial dependence (PDP) plots for more than one feature - part 3\n\nA PD plot can also be generated for two features and thus allow to inspect the interaction between\nthese features. Again, we'll look at acceleration_y and acceleration_z.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features = [[1, 2]]\nplot_partial_dependence(\n    automl,\n    dataset.data,\n    features=features,\n    grid_resolution=5,\n    feature_names=dataset.feature_names,\n)\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}